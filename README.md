# llm\_trainer: å…¨æµç¨‹å¤§æ¨¡å‹é«˜æ•ˆè®­ç»ƒæ¡†æ¶

`llm_trainer` æ˜¯ä¸€ä¸ªè½»é‡çº§ä½†åŠŸèƒ½å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŠè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è®­ç»ƒæ¡†æ¶ã€‚å®ƒæ”¯æŒä»**é¢„è®­ç»ƒ (Pretrain)**ã€**æœ‰ç›‘ç£å¾®è°ƒ (SFT)** åˆ° **äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹  (RLHF)** çš„å…¨æµç¨‹è®­ç»ƒï¼Œå¹¶å†…ç½®äº†å¯¹ DeepSpeed çš„æ·±åº¦é›†æˆã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

*   **å…¨ç”Ÿå‘½å‘¨æœŸæ”¯æŒ**ï¼šè¦†ç›– Pretrainã€SFTã€DPO (Direct Preference Optimization)ã€PPO (Proximal Policy Optimization) ä»¥åŠ GRPO (Group Relative Policy Optimization)ã€‚
*   **å¤šæ¨¡æ€æ”¯æŒ (VLM)**ï¼šåŸç”Ÿæ”¯æŒè§†è§‰è¯­è¨€æ¨¡å‹è®­ç»ƒï¼Œæ”¯æŒå›¾ç‰‡ Tag å¤„ç†ä¸ Pixel Value è½¬æ¢ï¼Œå¯å†»ç»“ LLM éƒ¨åˆ†ä»…è®­ç»ƒ Projectorã€‚
*   **é«˜æ•ˆæ•°æ®åŠ è½½**ï¼šæ”¯æŒ `.jsonl`ã€`.pkl` ä»¥åŠ **`.npy` (Memory Mapped)** æ ¼å¼ï¼Œæå¤§é™ä½æµ·é‡æ•°æ®è®­ç»ƒæ—¶çš„å†…å­˜å ç”¨ã€‚
*   **çµæ´»çš„å¹¶è¡Œç­–ç•¥**ï¼šå†…ç½® `smart_train` è„šæœ¬ï¼Œè‡ªåŠ¨è¯†åˆ«ç¯å¢ƒå¹¶åœ¨ DeepSpeed (Zero 0/1/2/3)ã€DDP å’Œå•æœºæ¨¡å¼é—´åˆ‡æ¢ã€‚
*   **ä¸°å¯Œçš„ Loss å®ç°**ï¼šå†…ç½® Critical Token Lossã€Aux Lossã€Knowledge Distillation (KD) Loss ä»¥åŠå¤šç§ RL Loss å®ç°ã€‚
*   **å®ç”¨å·¥å…·ç®±**ï¼šåŒ…å« Tokenizer å°è£…ã€å­¦ä¹ ç‡å¯è§†åŒ–ã€Loss æ›²çº¿ç»˜åˆ¶ã€æ–­ç‚¹ç»­è®­ç®¡ç†ç­‰å·¥å…·ã€‚

## ğŸ› ï¸ å®‰è£…

å¯ä»¥é€šè¿‡ pip å®‰è£…ï¼Œæˆ–ç›´æ¥ä»æºç å®‰è£…ï¼š


``` Bash
# ç›´æ¥å®‰è£…
pip3 install project_llm_trainer

# æºç å®‰è£…
git clone https://github.com/qibin0506/llm_trainer.git
cd llm_trainer
pip install -e .

```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. é…ç½®ç¯å¢ƒå˜é‡

é¡¹ç›®ä¾èµ–ç¯å¢ƒå˜é‡æ¥å®šä½èµ„æºï¼Œè¯·åœ¨è¿è¡Œå‰è®¾ç½®ï¼š

``` Python
import os

def init_env():
    # Tokenizer è·¯å¾„ (å¿…é¡»)
    os.environ['TOKEN_DIR'] = './tokens/'
    # æ—¥å¿—ä¸ Checkpoint ç›®å½•
    os.environ['LOG_DIR'] = './log/'
    # DeepSpeed Checkpoint ç›®å½•
    os.environ['DIST_CHECKPOINT_DIR'] = 'ckpt_dir'
    # å¸¸ç”¨é…ç½®
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    os.environ['CKPT_MAX_TO_KEEP'] = '2' # æœ€å¤šä¿ç•™å‡ ä¸ªckpt

```

### 2. å‡†å¤‡æ•°æ®

æ•°æ®æ ¼å¼æ”¯æŒçµæ´»é…ç½®ï¼Œæ¨èä½¿ç”¨ `.npy` æ ¼å¼ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

*è¯¦ç»†æ•°æ®ç”Ÿæˆç¤ºä¾‹è¯·å‚è€ƒ [example/create\_dataset.md](https://www.google.com/search?q=example/create_dataset.md)*ã€‚

### 3. å¼€å¯è®­ç»ƒ

#### é¢„è®­ç»ƒ (Pretrain)

``` Python
from llm_trainer import Trainer
from utils import init_env, get_pretrain_config

if __name__ == '__main__':
    init_env()
    trainer = Trainer(
        train_config=get_pretrain_config(),
        eval_prompts=['æµ‹è¯•prompt']
    )
    trainer.train()

```

#### æœ‰ç›‘ç£å¾®è°ƒ (SFT) & VLM

``` Python
from llm_trainer import SFTTrainer

# VLM é…ç½®ç¤ºä¾‹ï¼šå¯åœ¨ SFTConfig ä¸­æŒ‡å®š pixel_values_provider
trainer = SFTTrainer(
    train_config=get_sft_config(), 
    eval_prompts=['<image>æè¿°è¿™å¼ å›¾ç‰‡'],
    eval_image_tags=['./test.jpg'] # å¦‚æœæ˜¯VLM
)
trainer.train()

```

#### å¼ºåŒ–å­¦ä¹  (GRPO / PPO / DPO)

ä»¥ GRPO ä¸ºä¾‹ï¼š

``` Python
from llm_trainer import GRPOTrainer

# è‡ªå®šä¹‰ Reward Function
def reward_func(prompts, completions, answers):
    return [1.0 if len(c) > 10 else 0.0 for c in completions]

trainer = GRPOTrainer(
    train_config=get_grpo_config(),
    reward_func=reward_func,
    eval_prompts=['æµ‹è¯•ä¸€ä¸‹']
)
trainer.train()

```

***

## âš™ï¸ è®­ç»ƒå‚æ•°è¯¦è§£

æ‰€æœ‰é…ç½®å‡é€šè¿‡ `llm_trainer.train_configs` ä¸­çš„ Dataclass å®šä¹‰ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†å‚æ•°è¯´æ˜ã€‚

### 1. TrainConfig (ä¸»é…ç½®)

`TrainConfig` æ˜¯è®­ç»ƒçš„æ ¸å¿ƒå…¥å£ï¼Œæ§åˆ¶å…¨å±€å‚æ•°ã€‚

| **å‚æ•°å**              | **ç±»å‹**             | **è¯´æ˜**                                                        |
| :------------------- | :----------------- | :------------------------------------------------------------ |
| `n_epochs`           | `int`              | è®­ç»ƒçš„æ€»è½®æ•° (Epochs)                                               |
| `batch_size`         | `int`              | æ¯ä¸ª GPU çš„å¾®æ‰¹æ¬¡å¤§å° (Micro Batch Size)                              |
| `model_config`       | `ModelConfig`      | æ¨¡å‹ç»“æ„é…ç½® (Hidden size, Layers ç­‰)                                |
| `file_dataset`       | `FileDataset`      | è®­ç»ƒæ•°æ®é›†å®ä¾‹                                                       |
| `dataset_block_size` | `int`              | è®­ç»ƒåºåˆ—çš„æœ€å¤§é•¿åº¦ (Seq Len)ã€‚è‹¥ä¸º `None` åˆ™å–æ¨¡å‹çš„ `max_position_embeddings` |
| `init_state_dict`    | `dict`             | (å¯é€‰) åˆå§‹åŒ–çš„æ¨¡å‹æƒé‡ï¼Œç”¨äºæ–­ç‚¹ç»­è®­æˆ–åŠ è½½é¢„è®­ç»ƒæƒé‡                                  |
| `data_loader_config` | `DataLoaderConfig` | æ•°æ®åŠ è½½å™¨é…ç½® (è§ä¸‹æ–‡)                                                 |
| `loss_config`        | `LossConfig`       | æŸå¤±å‡½æ•°é…ç½® (è§ä¸‹æ–‡)                                                  |
| `optim_config`       | `OptimConfig`      | ä¼˜åŒ–å™¨é…ç½® (è§ä¸‹æ–‡)                                                   |
| `ds_config`          | `DsConfig`         | DeepSpeed é…ç½® (è§ä¸‹æ–‡)                                            |
| `eval_config`        | `EvalConfig`       | è¯„ä¼°ç”Ÿæˆé…ç½® (è§ä¸‹æ–‡)                                                  |

### 2. OptimConfig (ä¼˜åŒ–å™¨é…ç½®)

æ§åˆ¶å­¦ä¹ ç‡è°ƒåº¦å’Œä¼˜åŒ–å™¨è¡Œä¸ºã€‚

| **å‚æ•°å**                   | **ç±»å‹**  | **é»˜è®¤å€¼**  | **è¯´æ˜**                         |
| :------------------------ | :------ | :------- | :----------------------------- |
| `optim_type`              | `str`   | `'adam'` | ä¼˜åŒ–å™¨ç±»å‹ï¼Œæ”¯æŒ `'adam'` æˆ– `'lion'`   |
| `enable_lr_scheduler`     | `bool`  | `False`  | æ˜¯å¦å¯ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨                     |
| `initial_lr`              | `float` | -        | **åˆå§‹å­¦ä¹ ç‡** (Warmup ç»“æŸåçš„æœ€é«˜å­¦ä¹ ç‡)   |
| `min_lr`                  | `float` | -        | æœ€å°å­¦ä¹ ç‡ (ä½™å¼¦é€€ç«çš„ç»ˆç‚¹)                |
| `max_lr`                  | `float` | -        | (å¯é€‰) æœ€å¤§å­¦ä¹ ç‡ï¼Œé€šå¸¸ä¸ `initial_lr` ç›¸åŒ |
| `warmup_iters`            | `int`   | `None`   | é¢„çƒ­æ­¥æ•°                           |
| `weight_decay`            | `float` | `None`   | æƒé‡è¡°å‡ç³»æ•°                         |
| `betas`                   | `tuple` | `None`   | Adam æˆ– Lion çš„ beta å‚æ•°          |
| `cosine_annealing_period` | `int`   | `None`   | ä½™å¼¦é€€ç«å‘¨æœŸæ­¥æ•°                       |

### 3. DsConfig (DeepSpeed é…ç½®)

æ§åˆ¶åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ã€‚

| **å‚æ•°å**                    | **ç±»å‹**                            | **è¯´æ˜**                                         |
| :------------------------- | :-------------------------------- | :--------------------------------------------- |
| `zero_config`              | `DsZeROConfig`                    | ZeRO ä¼˜åŒ–é…ç½® (`DsZero0Config` \~ `DsZero3Config`) |
| `fp16_config`              | `DsFp16Config`                    | FP16 æ··åˆç²¾åº¦é…ç½® (`enabled=True/False`)             |
| `bf16_config`              | `DsBf16Config`                    | BF16 æ··åˆç²¾åº¦é…ç½® (`enabled=True/False`)             |
| `gradient_clipping`        | `float`                           | æ¢¯åº¦è£å‰ªé˜ˆå€¼ (é»˜è®¤ 1.0)                                |
| `activation_checkpointing` | `DsActivationCheckpointingConfig` | æ¿€æ´»é‡è®¡ç®— (æ¢¯åº¦æ£€æŸ¥ç‚¹) é…ç½®ï¼Œç”¨äºèŠ‚çœæ˜¾å­˜                        |

### 4. é˜¶æ®µä¸“å±é…ç½®

æ ¹æ®ä¸åŒçš„ `Trainer`ï¼Œéœ€è¦ä¼ å…¥å¯¹åº”çš„ä¸“å±é…ç½®å¯¹è±¡ã€‚

#### SFTConfig (æœ‰ç›‘ç£å¾®è°ƒ)

| **å‚æ•°å**                       | **ç±»å‹**     | **é»˜è®¤å€¼** | **è¯´æ˜**                               |
| :---------------------------- | :--------- | :------ | :----------------------------------- |
| `mask_prompt`                 | `bool`     | `True`  | æ˜¯å¦åœ¨è®¡ç®— Loss æ—¶å±è”½ Prompt éƒ¨åˆ†             |
| `freeze_llm_model`            | `bool`     | `False` | æ˜¯å¦å†»ç»“ LLM å‚æ•° (ç”¨äº VLM è®­ç»ƒ)              |
| `pixel_values_provider`       | `Callable` | `None`  | (VLM) æ ¹æ® Image Tag è·å–å›¾ç‰‡ Tensor çš„å›è°ƒå‡½æ•° |
| `gradient_accumulation_steps` | `int`      | `1`     | æ¢¯åº¦ç´¯ç§¯æ­¥æ•°                               |

#### DPOConfig (åå¥½ä¼˜åŒ–)

| **å‚æ•°å**                | **ç±»å‹**  | **é»˜è®¤å€¼** | **è¯´æ˜**               |
| :--------------------- | :------ | :------ | :------------------- |
| `ref_model_checkpoint` | `dict`  | -       | å‚è€ƒæ¨¡å‹ (Ref Model) çš„æƒé‡ |
| `loss_beta`            | `float` | -       | DPO çš„ KL æƒ©ç½šç³»æ•° beta   |
| `loss_label_smoothing` | `float` | `0.0`   | æ ‡ç­¾å¹³æ»‘ç³»æ•°               |
| `nll_loss_coef`        | `float` | `None`  | (å¯é€‰) NLL Loss çš„è¾…åŠ©ç³»æ•°  |

#### PPOConfig (å¼ºåŒ–å­¦ä¹ )

| **å‚æ•°å**                  | **ç±»å‹**  | **è¯´æ˜**                            |
| :----------------------- | :------ | :-------------------------------- |
| `ppo_epochs`             | `int`   | æ¯æ¬¡é‡‡é›†æ•°æ®åï¼ŒPPO æ›´æ–°çš„è½®æ•°                 |
| `ppo_batch_size`         | `int`   | PPO æ›´æ–°æ—¶çš„ mini-batch å¤§å°            |
| `vf_coef`                | `float` | Value Function Loss çš„ç³»æ•° (é€šå¸¸ 0.5)  |
| `kl_beta`                | `float` | KL æ•£åº¦æƒ©ç½šç³»æ•°                         |
| `kl_estimator`           | `str`   | KL ä¼°è®¡å™¨ç±»å‹ (`'k1'` æˆ– `'k3'`)        |
| `normalize_rewards`      | `bool`  | æ˜¯å¦å¯¹ Reward è¿›è¡Œæ ‡å‡†åŒ– (RunningMeanStd) |
| `gen_max_seq_len`        | `int`   | ç”Ÿæˆé‡‡æ ·çš„æœ€å¤§é•¿åº¦                         |
| `gen_temperature`        | `float` | é‡‡æ ·æ¸©åº¦                              |
| `ref_model_checkpoint`   | `dict`  | å‚è€ƒæ¨¡å‹æƒé‡                            |
| `value_model_checkpoint` | `dict`  | (å¯é€‰) ç‹¬ç«‹çš„ Value Model æƒé‡           |

#### GRPOConfig (ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–)

| **å‚æ•°å**           | **ç±»å‹**  | **è¯´æ˜**                              |
| :---------------- | :------ | :---------------------------------- |
| `group_size`      | `int`   | æ¯ç»„é‡‡æ ·çš„æ ·æœ¬æ•°é‡ (G)                       |
| `grpo_steps`      | `int`   | æ¯æ‰¹æ•°æ®æ›´æ–°çš„æ­¥æ•°                           |
| `loss_beta`       | `float` | KL æƒ©ç½šé¡¹ç³»æ•° (GRPO ä¸­é€šå¸¸è®¾ä¸º 0 æˆ–å¾ˆå°)         |
| `loss_type`       | `str`   | Loss ç±»å‹ï¼Œæ”¯æŒ `'grpo'` (é»˜è®¤) æˆ– `'bnpo'` |
| `mixup_alpha`     | `float` | è®­ç»ƒæ¨¡å‹ä¸ Ref æ¨¡å‹å‚æ•°æ··åˆç³»æ•° (é»˜è®¤ 1.0ï¼Œå³ä¸æ··åˆ)    |
| `gen_max_seq_len` | `int`   | ç”Ÿæˆæœ€å¤§é•¿åº¦                              |

### 5. å…¶ä»–é…ç½®

*   **DataLoaderConfig**: `data_loader_num_workers`, `data_loader_pin_memory`, `data_loader_shuffle` (æ˜¯å¦æ‰“ä¹±æ•°æ®)ã€‚
*   **EvalConfig**: `eval_batch_interval` (æ¯éš”å¤šå°‘ Batch è¯„ä¼°ä¸€æ¬¡), `max_seq_len` (è¯„ä¼°ç”Ÿæˆé•¿åº¦)ã€‚
*   **LossConfig**: `aux_loss_coef` (MoE è´Ÿè½½å‡è¡¡ Loss ç³»æ•°), `critical_tokens` (å…³é”® Token ID åˆ—è¡¨, ç”¨äºåŠ æƒ Loss)ã€‚
*   **KDConfig**: çŸ¥è¯†è’¸é¦é…ç½®ï¼Œéœ€æä¾› `teacher_logits_provider`ã€‚

***

## ğŸ–¥ï¸ å¯åŠ¨è„šæœ¬

é¡¹ç›®å†…ç½®äº†æ™ºèƒ½å¯åŠ¨å‘½ä»¤ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™å¤æ‚çš„ `torchrun` æˆ– `deepspeed` æŒ‡ä»¤ã€‚

| **å‘½ä»¤**            | **æè¿°**                                                      | **ç¤ºä¾‹**                            |
| :---------------- | :---------------------------------------------------------- | :-------------------------------- |
| **`smart_train`** | **æ¨è**ã€‚è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒã€‚ä¼˜å…ˆä½¿ç”¨ DeepSpeedï¼Œæœªå®‰è£…åˆ™é™çº§ä¸º DDPï¼Œå•å¡åˆ™ä½¿ç”¨ Python åŸç”Ÿè¿è¡Œã€‚ | `smart_train train_pretrain.py`   |
| **`ds_train`**    | å¼ºåˆ¶ä½¿ç”¨ DeepSpeed å¯åŠ¨ã€‚                                          | `ds_train train_sft.py --arg1 v1` |
| **`ddp_train`**   | å¼ºåˆ¶ä½¿ç”¨ DDP (torchrun) å¯åŠ¨ã€‚                                     | `ddp_train train_ppo.py`          |

## ğŸ“Š å¯è§†åŒ–ä¸å…¶ä»–å·¥å…·

é¡¹ç›®åœ¨ `scripts` ç›®å½•ä¸‹æä¾›äº†ä¸€ç³»åˆ—è¾…åŠ©è„šæœ¬ï¼š

*   **`vis_log`**: ç»˜åˆ¶è®­ç»ƒæ—¥å¿—æ›²çº¿ï¼ˆLoss, Reward, Aux Loss ç­‰ï¼‰ã€‚

    Bash

    ```
    vis_log ./log/log.txt

    ```
*   **`vis_lr`**: å¯è§†åŒ–å­¦ä¹ ç‡å˜åŒ–æ›²çº¿ã€‚

    Bash

    ```
    vis_lr ./log/lr.txt

    ```
*   **`calc_intermediate_size`**: è¾…åŠ©è®¡ç®—æ¨¡å‹å‚æ•°ï¼ˆå¦‚ FFN çš„ intermediate sizeï¼‰ã€‚

    Bash

    ```
    calc_intermediate_size 4096 # è¾“å…¥ hidden_size

    ```
